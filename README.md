# AgenticMultiModalQASystem

This is a LangGraph-powered multi-agent system that analyzes images and answers user questions using vision-language models (VLMs).

## ðŸ§  Features
- Vision analysis via GPT-4 Vision
- Natural language question parsing
- Optional knowledge lookup agent
- Multi-step graph execution with memory
- Extendable and inspectable via LangGraph

## ðŸ“Š Benchmark

This system can be evaluated on benchmarks such as:

- [SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers (NeurIPS 2024)](https://arxiv.org/abs/2407.09413)


## ðŸš€ Usage

### 1. Install dependencies
```bash
pip install -r requirements.txt
